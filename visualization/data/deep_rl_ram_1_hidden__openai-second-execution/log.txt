Logging to C:\Users\dalme\AppData\Local\Temp\openai-2018-06-25-21-41-19-434859
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 100      |
| mean 100 episode reward | 1.2      |
| steps                   | 17956    |
--------------------------------------
Saving model due to mean reward increase: None -> 1.2
Saving model due to mean reward increase: 1.2 -> 1.3
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 200      |
| mean 100 episode reward | 1.5      |
| steps                   | 37617    |
--------------------------------------
Saving model due to mean reward increase: 1.3 -> 1.4
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 300      |
| mean 100 episode reward | 1.3      |
| steps                   | 57213    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 400      |
| mean 100 episode reward | 1.4      |
| steps                   | 78239    |
--------------------------------------
Saving model due to mean reward increase: 1.4 -> 1.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 500      |
| mean 100 episode reward | 1.6      |
| steps                   | 106125   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 600      |
| mean 100 episode reward | 1.5      |
| steps                   | 144685   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 700      |
| mean 100 episode reward | 1.6      |
| steps                   | 179995   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 800      |
| mean 100 episode reward | 1.3      |
| steps                   | 213733   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 900      |
| mean 100 episode reward | 1.3      |
| steps                   | 249141   |
--------------------------------------
Saving model due to mean reward increase: 1.6 -> 1.7
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1000     |
| mean 100 episode reward | 1.4      |
| steps                   | 285145   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1100     |
| mean 100 episode reward | 1.3      |
| steps                   | 320320   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1200     |
| mean 100 episode reward | 1.5      |
| steps                   | 356865   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1300     |
| mean 100 episode reward | 1.7      |
| steps                   | 387701   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1400     |
| mean 100 episode reward | 1.2      |
| steps                   | 419605   |
--------------------------------------
Saving model due to mean reward increase: 1.7 -> 1.9
Saving model due to mean reward increase: 1.9 -> 2.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1500     |
| mean 100 episode reward | 2        |
| steps                   | 450692   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1600     |
| mean 100 episode reward | 1.7      |
| steps                   | 483459   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1700     |
| mean 100 episode reward | 1.5      |
| steps                   | 510596   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1800     |
| mean 100 episode reward | 1.6      |
| steps                   | 545243   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 1900     |
| mean 100 episode reward | 1.2      |
| steps                   | 578133   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2000     |
| mean 100 episode reward | 1.6      |
| steps                   | 607205   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2100     |
| mean 100 episode reward | 1.4      |
| steps                   | 637081   |
--------------------------------------
Saving model due to mean reward increase: 2.0 -> 2.2
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2200     |
| mean 100 episode reward | 2.4      |
| steps                   | 666198   |
--------------------------------------
Saving model due to mean reward increase: 2.2 -> 2.6
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2300     |
| mean 100 episode reward | 2.4      |
| steps                   | 698145   |
--------------------------------------
Saving model due to mean reward increase: 2.6 -> 2.7
Saving model due to mean reward increase: 2.7 -> 2.8
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2400     |
| mean 100 episode reward | 2.8      |
| steps                   | 726103   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2500     |
| mean 100 episode reward | 2.3      |
| steps                   | 755302   |
--------------------------------------
Saving model due to mean reward increase: 2.8 -> 3.0
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2600     |
| mean 100 episode reward | 2.8      |
| steps                   | 784082   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2700     |
| mean 100 episode reward | 2        |
| steps                   | 815296   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2800     |
| mean 100 episode reward | 2.6      |
| steps                   | 845299   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 2900     |
| mean 100 episode reward | 2        |
| steps                   | 877118   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3000     |
| mean 100 episode reward | 2.2      |
| steps                   | 911081   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3100     |
| mean 100 episode reward | 2        |
| steps                   | 946315   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 3200     |
| mean 100 episode reward | 2.8      |
| steps                   | 983369   |
--------------------------------------
Restored model with mean reward: 3.0
